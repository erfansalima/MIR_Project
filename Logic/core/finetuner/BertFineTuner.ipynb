{
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "accelerator": "GPU",
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30733,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "First Downlad the Dataset"
   ],
   "metadata": {
    "id": "yiIkxdkJXMFt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!conda install -y gdown"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:17:08.388847Z",
     "iopub.execute_input": "2024-06-25T10:17:08.389466Z",
     "iopub.status.idle": "2024-06-25T10:18:25.216653Z",
     "shell.execute_reply.started": "2024-06-25T10:17:08.389414Z",
     "shell.execute_reply": "2024-06-25T10:18:25.215462Z"
    },
    "trusted": true
   },
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Channels:\n - rapidsai\n - nvidia\n - conda-forge\n - defaults\n - pytorch\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - gdown\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    packaging-24.1             |     pyhd8ed1ab_0          49 KB  conda-forge\n    pluggy-1.5.0               |     pyhd8ed1ab_0          23 KB  conda-forge\n    requests-2.32.3            |     pyhd8ed1ab_0          57 KB  conda-forge\n    tqdm-4.66.4                |     pyhd8ed1ab_0          87 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         217 KB\n\nThe following NEW packages will be INSTALLED:\n\n  packaging          conda-forge/noarch::packaging-24.1-pyhd8ed1ab_0 \n  pluggy             conda-forge/noarch::pluggy-1.5.0-pyhd8ed1ab_0 \n  requests           conda-forge/noarch::requests-2.32.3-pyhd8ed1ab_0 \n  tqdm               conda-forge/noarch::tqdm-4.66.4-pyhd8ed1ab_0 \n\n\n\nDownloading and Extracting Packages:\ntqdm-4.66.4          | 87 KB     |                                       |   0% \nrequests-2.32.3      | 57 KB     |                                       |   0% \u001B[A\n\npackaging-24.1       | 49 KB     |                                       |   0% \u001B[A\u001B[A\n\n\npluggy-1.5.0         | 23 KB     |                                       |   0% \u001B[A\u001B[A\u001B[A\nrequests-2.32.3      | 57 KB     | ##########3                           |  28% \u001B[A\n\n\npluggy-1.5.0         | 23 KB     | ##################################### | 100% \u001B[A\u001B[A\u001B[A\n\n\npluggy-1.5.0         | 23 KB     | ##################################### | 100% \u001B[A\u001B[A\u001B[A\n\npackaging-24.1       | 49 KB     | ##################################### | 100% \u001B[A\u001B[A\n\npackaging-24.1       | 49 KB     | ##################################### | 100% \u001B[A\u001B[A\n                                                                                \u001B[A\n                                                                                \u001B[A\n\n                                                                                \u001B[A\u001B[A\n\n\n                                                                                \u001B[A\u001B[A\u001B[A\nPreparing transaction: done\nVerifying transaction: failed\n\nRemoveError: 'packaging' is a dependency of conda and cannot be removed from\nconda's operating environment.\nRemoveError: 'pluggy' is a dependency of conda and cannot be removed from\nconda's operating environment.\nRemoveError: 'requests' is a dependency of conda and cannot be removed from\nconda's operating environment.\nRemoveError: 'tqdm' is a dependency of conda and cannot be removed from\nconda's operating environment.\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!gdown --id 1Lq2zVJlN_B4kUAu4VafQ4jXMIQiAR9vI"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:18:25.219196Z",
     "iopub.execute_input": "2024-06-25T10:18:25.219654Z",
     "iopub.status.idle": "2024-06-25T10:18:28.894712Z",
     "shell.execute_reply.started": "2024-06-25T10:18:25.219600Z",
     "shell.execute_reply": "2024-06-25T10:18:28.893478Z"
    },
    "trusted": true
   },
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "text": "/opt/conda/lib/python3.10/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1Lq2zVJlN_B4kUAu4VafQ4jXMIQiAR9vI\nFrom (redirected): https://drive.google.com/uc?id=1Lq2zVJlN_B4kUAu4VafQ4jXMIQiAR9vI&confirm=t&uuid=e8a5fb7c-3a72-490e-ae71-44b43dfeac8e\nTo: /kaggle/working/IMDB_crawled.json\n100%|█████████████████████████████████████████| 292M/292M [00:01<00:00, 191MB/s]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download Requirements"
   ],
   "metadata": {
    "id": "CShaeWVwXWic"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install accelerate -U\n",
    "!pip install transformers[torch]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bTvY67YhykKv",
    "outputId": "2f9c41ee-8f77-49a3-a402-ccd795296c1f",
    "execution": {
     "iopub.status.busy": "2024-06-25T10:18:28.896928Z",
     "iopub.execute_input": "2024-06-25T10:18:28.897727Z",
     "iopub.status.idle": "2024-06-25T10:18:53.603942Z",
     "shell.execute_reply.started": "2024-06-25T10:18:28.897676Z",
     "shell.execute_reply": "2024-06-25T10:18:53.602834Z"
    },
    "trusted": true
   },
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.31.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.41.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.23.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.31.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2024.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.6.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocess the Dataset and save it to IMDB_crawled(preprocessed).json"
   ],
   "metadata": {
    "id": "TZJXVx8kXdT_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "class Preprocessor:\n",
    "\n",
    "    def __init__(self, documents: list):\n",
    "        \"\"\"\n",
    "        Initialize the class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        documents : list\n",
    "            The list of documents to be preprocessed.\n",
    "        \"\"\"\n",
    "        self.documents = documents\n",
    "        nltk.download('stopwords')\n",
    "        nltk.download('punkt')\n",
    "        nltk.download('wordnet')\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "\n",
    "    def preprocess(self):\n",
    "        \"\"\"\n",
    "        Preprocess the text using the methods in the class.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        List[str]\n",
    "            The preprocessed documents.\n",
    "        \"\"\"\n",
    "        preprocessed_documents = []\n",
    "        for doc in self.documents:\n",
    "            preprocessed_doc = doc.copy()  # Copy the document to avoid modifying the original\n",
    "            if 'first_page_summary' in doc:\n",
    "                preprocessed_doc['first_page_summary'] = self.preprocess_attribute(doc['first_page_summary'])\n",
    "            preprocessed_documents.append(preprocessed_doc)\n",
    "        return preprocessed_documents\n",
    "\n",
    "    def preprocess_attribute(self, attribute):\n",
    "        \"\"\"\n",
    "        Preprocess a single attribute.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        attribute : str or List[str] or None\n",
    "            The attribute value to be preprocessed.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        str or List[str] or None\n",
    "            The preprocessed attribute value.\n",
    "        \"\"\"\n",
    "        if isinstance(attribute, str):\n",
    "            attribute = self.normalize(attribute)\n",
    "            attribute = self.remove_links(attribute)\n",
    "            attribute = self.remove_punctuations(attribute)\n",
    "            attribute = self.tokenize(attribute)\n",
    "            attribute = self.remove_stopwords(attribute)\n",
    "        elif isinstance(attribute, list):\n",
    "            attribute = [self.preprocess_attribute(item) for item in attribute]\n",
    "        return attribute\n",
    "\n",
    "    def normalize(self, text: str):\n",
    "        \"\"\"\n",
    "        Normalize the text by converting it to a lower case, stemming, lemmatization, etc.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "            The text to be normalized.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        str\n",
    "            The normalized text.\n",
    "        \"\"\"\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = word_tokenize(text)\n",
    "        normalized_text = ' '.join(words)\n",
    "        normalized_text = re.sub(r'\\b\\w*\\d\\w*\\b', '', normalized_text)\n",
    "        return normalized_text.lower()\n",
    "\n",
    "    def remove_links(self, text: str):\n",
    "        \"\"\"\n",
    "        Remove links from the text.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "            The text to be processed.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        str\n",
    "            The text with links removed.\n",
    "        \"\"\"\n",
    "        patterns = [r'\\S*http\\S*', r'\\S*www\\S*', r'\\S+\\.ir\\S*', r'\\S+\\.com\\S*', r'\\S+\\.org\\S*', r'\\S*@\\S*']\n",
    "        for pattern in patterns:\n",
    "            text = re.sub(pattern, '', text)\n",
    "        return text\n",
    "\n",
    "    def remove_punctuations(self, text: str):\n",
    "        \"\"\"\n",
    "        Remove punctuations from the text.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "            The text to be processed.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        str\n",
    "            The text with punctuations removed.\n",
    "        \"\"\"\n",
    "        return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    def tokenize(self, text: str):\n",
    "        \"\"\"\n",
    "        Tokenize the words in the text.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "            The text to be tokenized.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        list\n",
    "            The list of words.\n",
    "        \"\"\"\n",
    "        return word_tokenize(text)\n",
    "\n",
    "    def remove_stopwords(self, tokens: list):\n",
    "        \"\"\"\n",
    "        Remove stopwords from the text.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tokens : list\n",
    "            The list of tokens to remove stopwords from.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        str\n",
    "            The text with stopwords removed.\n",
    "        \"\"\"\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in self.stopwords and not any(char.isdigit() for char in token)]\n",
    "        return ' '.join(filtered_tokens)\n",
    "\n",
    "\n",
    "with open('IMDB_crawled.json', 'r') as f:\n",
    "    x = json.load(f)\n",
    "\n",
    "preprocessor = Preprocessor(x)\n",
    "prep = preprocessor.preprocess()\n",
    "\n",
    "with open('IMDB_crawled(preprocessed).json', 'w') as f:\n",
    "    json.dump(prep, f, indent=4)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NiKsUO9gXpUi",
    "outputId": "0cde6148-edd1-4ab4-e0ac-73b17c4c2906",
    "execution": {
     "iopub.status.busy": "2024-06-25T10:18:53.607207Z",
     "iopub.execute_input": "2024-06-25T10:18:53.607564Z",
     "iopub.status.idle": "2024-06-25T10:19:06.737721Z",
     "shell.execute_reply.started": "2024-06-25T10:18:53.607531Z",
     "shell.execute_reply": "2024-06-25T10:19:06.736375Z"
    },
    "trusted": true
   },
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "text": "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Class BERTFinetuner"
   ],
   "metadata": {
    "id": "0lptU1LPYViu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from huggingface_hub import login, create_repo\n",
    "\n",
    "\n",
    "class BERTFinetuner:\n",
    "    \"\"\"\n",
    "    A class for fine-tuning the BERT model on a movie genre classification task.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_path, top_n_genres=5):\n",
    "        \"\"\"\n",
    "        Initialize the BERTFinetuner class.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): The path to the JSON file containing the dataset.\n",
    "            top_n_genres (int): The number of top genres to consider.\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.top_n_genres = top_n_genres\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=self.top_n_genres)\n",
    "        self.df = None\n",
    "        self.train_data = None\n",
    "        self.val_data = None\n",
    "        self.test_data = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "\n",
    "    def load_dataset(self):\n",
    "        \"\"\"\n",
    "        Load the dataset from the JSON file.\n",
    "        \"\"\"\n",
    "        with open(self.file_path, 'r') as f:\n",
    "            self.df = json.load(f)\n",
    "        print(\"Dataset loaded successfully.\")\n",
    "\n",
    "    def preprocess_genre_distribution(self):\n",
    "        \"\"\"\n",
    "        Preprocess the dataset by filtering for the top n genres\n",
    "        \"\"\"\n",
    "        genres = [entry['genres'] for entry in self.df]\n",
    "        genre_counts = Counter([genre for sublist in genres for genre in sublist])\n",
    "        top_genres = [genre for genre, _ in genre_counts.most_common(self.top_n_genres)]\n",
    "\n",
    "        filtered_dataset = []\n",
    "        for entry in self.df:\n",
    "            entry_genres = [genre for genre in entry['genres'] if genre in top_genres]\n",
    "            if entry_genres:\n",
    "                entry['genres'] = entry_genres\n",
    "                filtered_dataset.append(entry)\n",
    "\n",
    "        self.df = filtered_dataset\n",
    "\n",
    "        top_genre_counts = {genre: genre_counts[genre] for genre in top_genres}\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x=list(top_genre_counts.keys()), y=list(top_genre_counts.values()))\n",
    "        plt.title('Top Genres Distribution')\n",
    "        plt.xlabel('Genres')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def split_dataset(self, test_size=0.2, val_size=0.5):\n",
    "        \"\"\"\n",
    "        Split the dataset into train, validation, and test sets.\n",
    "\n",
    "        Args:\n",
    "            test_size (float): The proportion of the dataset to include in the test split.\n",
    "            val_size (float): The proportion of the dataset to include in the validation split.\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame(self.df)\n",
    "        X = df[\"first_page_summary\"].tolist()\n",
    "        y = df['genres'].str[0].tolist()\n",
    "        y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "        X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp,test_size=val_size, random_state=42)\n",
    "\n",
    "        self.train_data = self.create_dataset(X_train, y_train)\n",
    "        self.val_data = self.create_dataset(X_val, y_val)\n",
    "        self.test_data = self.create_dataset(X_test, y_test)\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "        print(\"Dataset split into train, validation, and test sets.\")\n",
    "\n",
    "\n",
    "    def create_dataset(self, encodings, labels):\n",
    "        \"\"\"\n",
    "        Create a PyTorch dataset from the given encodings and labels.\n",
    "\n",
    "        Args:\n",
    "            encodings (dict): The tokenized input encodings.\n",
    "            labels (list): The corresponding labels.\n",
    "\n",
    "        Returns:\n",
    "            IMDbDataset: A PyTorch dataset object.\n",
    "        \"\"\"\n",
    "        encodings = self.tokenizer(list(map(str, encodings)), truncation=True, padding=True)\n",
    "        return IMDbDataset(encodings, labels)\n",
    "\n",
    "    def fine_tune_bert(self, epochs=5, batch_size=16, warmup_steps=500, weight_decay=0.01):\n",
    "        \"\"\"\n",
    "        Fine-tune the BERT model on the training data.\n",
    "\n",
    "        Args:\n",
    "            epochs (int): The number of training epochs.\n",
    "            batch_size (int): The batch size for training.\n",
    "            warmup_steps (int): The number of warmup steps for the learning rate scheduler.\n",
    "            weight_decay (float): The strength of weight decay regularization.\n",
    "        \"\"\"\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir='./results',\n",
    "            num_train_epochs=epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            warmup_steps=warmup_steps,\n",
    "            weight_decay=weight_decay,\n",
    "            logging_dir='./logs',\n",
    "            logging_steps=10,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\"\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=self.train_data,\n",
    "            eval_dataset=self.val_data,\n",
    "            compute_metrics=self.compute_metrics\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        self.model = trainer\n",
    "\n",
    "    def compute_metrics(self, pred):\n",
    "        \"\"\"\n",
    "        Compute evaluation metrics based on the predictions.\n",
    "\n",
    "        Args:\n",
    "            pred (EvalPrediction): The model's predictions.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the computed metrics.\n",
    "        \"\"\"\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        \"\"\"\n",
    "        Evaluate the fine-tuned model on the test set.\n",
    "        \"\"\"\n",
    "        raw_pred, _, _ = self.model.predict(self.test_data)\n",
    "        y_pred = np.argmax(raw_pred, axis=1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(self.y_test, y_pred, average='weighted')\n",
    "        acc = accuracy_score(self.y_test, y_pred)\n",
    "        evaluation_metrics = {\n",
    "            'accuracy': acc,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "\n",
    "        print(evaluation_metrics)\n",
    "\n",
    "    def save_model(self, model_name):\n",
    "        \"\"\"\n",
    "        Save the fine-tuned model and tokenizer to the Hugging Face Hub.\n",
    "\n",
    "        Args:\n",
    "            model_name (str): The name of the model on the Hugging Face Hub.\n",
    "        \"\"\"\n",
    "        self.model.save_model(model_name)\n",
    "        self.tokenizer.save_pretrained(model_name)\n",
    "        token = \"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\"\n",
    "        login(token)\n",
    "        repo_url = create_repo(repo_id=model_name)\n",
    "    \n",
    "        self.model.push_to_hub(model_name, token)\n",
    "        self.tokenizer.push_to_hub(model_name,token)\n",
    "\n",
    "        print(f\"Model saved.\")\n",
    "\n",
    "\n",
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch dataset for the movie genre classification task.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encodings, labels):\n",
    "        \"\"\"\n",
    "        Initialize the IMDbDataset class.\n",
    "\n",
    "        Args:\n",
    "            encodings (dict): The tokenized input encodings.\n",
    "            labels (list): The corresponding labels.\n",
    "        \"\"\"\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a single item from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the item to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the input encodings and labels.\n",
    "        \"\"\"\n",
    "        # TODO: Implement item retrieval logic\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the length of the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: The number of items in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.labels)"
   ],
   "metadata": {
    "id": "xJ985w1VYXF7",
    "execution": {
     "iopub.status.busy": "2024-06-25T10:19:06.739279Z",
     "iopub.execute_input": "2024-06-25T10:19:06.739600Z",
     "iopub.status.idle": "2024-06-25T10:19:06.784871Z",
     "shell.execute_reply.started": "2024-06-25T10:19:06.739570Z",
     "shell.execute_reply": "2024-06-25T10:19:06.783756Z"
    },
    "trusted": true
   },
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "bert_finetuner = BERTFinetuner('IMDB_crawled(preprocessed).json', top_n_genres=5)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZZJPZQckeqo",
    "outputId": "420754b6-68d6-4214-ada4-6bb8a76449c2",
    "execution": {
     "iopub.status.busy": "2024-06-25T10:19:06.786531Z",
     "iopub.execute_input": "2024-06-25T10:19:06.786896Z",
     "iopub.status.idle": "2024-06-25T10:19:07.892263Z",
     "shell.execute_reply.started": "2024-06-25T10:19:06.786860Z",
     "shell.execute_reply": "2024-06-25T10:19:07.890489Z"
    },
    "trusted": true
   },
   "execution_count": 54,
   "outputs": [
    {
     "name": "stderr",
     "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "bert_finetuner.load_dataset()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZw6FdiikpaC",
    "outputId": "d3ac9e5e-4702-4a5a-e46b-82cfb64cf660",
    "execution": {
     "iopub.status.busy": "2024-06-25T10:19:07.893477Z",
     "iopub.execute_input": "2024-06-25T10:19:07.893826Z",
     "iopub.status.idle": "2024-06-25T10:19:09.248863Z",
     "shell.execute_reply.started": "2024-06-25T10:19:07.893801Z",
     "shell.execute_reply": "2024-06-25T10:19:09.247648Z"
    },
    "trusted": true
   },
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "text": "Dataset loaded successfully.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Preprocess genre distribution\n",
    "bert_finetuner.preprocess_genre_distribution()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "7F2yarxQks11",
    "outputId": "3f838cb2-1ab7-48f3-9ef7-9d7d6e0d9d4e",
    "execution": {
     "iopub.status.busy": "2024-06-25T10:19:09.250290Z",
     "iopub.execute_input": "2024-06-25T10:19:09.250940Z",
     "iopub.status.idle": "2024-06-25T10:19:09.562304Z",
     "shell.execute_reply.started": "2024-06-25T10:19:09.250903Z",
     "shell.execute_reply": "2024-06-25T10:19:09.560801Z"
    },
    "trusted": true
   },
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1765: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n  order = pd.unique(vector)\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Split the dataset\n",
    "bert_finetuner.split_dataset()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efSeUQueoNp0",
    "outputId": "f1ca0ba2-d5be-4320-8d5d-3f20fa66aede",
    "execution": {
     "iopub.status.busy": "2024-06-25T10:19:09.563486Z",
     "iopub.execute_input": "2024-06-25T10:19:09.563838Z",
     "iopub.status.idle": "2024-06-25T10:19:15.685777Z",
     "shell.execute_reply.started": "2024-06-25T10:19:09.563806Z",
     "shell.execute_reply": "2024-06-25T10:19:15.684514Z"
    },
    "trusted": true
   },
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "text": "Dataset split into train, validation, and test sets.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Fine-tune BERT model\n",
    "bert_finetuner.fine_tune_bert()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "mCZXfxYZox8g",
    "outputId": "8646184c-f36e-4434-dbf5-d74e657ec841",
    "execution": {
     "iopub.status.busy": "2024-06-25T10:19:15.689562Z",
     "iopub.execute_input": "2024-06-25T10:19:15.689975Z",
     "iopub.status.idle": "2024-06-25T10:24:23.776767Z",
     "shell.execute_reply.started": "2024-06-25T10:19:15.689937Z",
     "shell.execute_reply": "2024-06-25T10:24:23.775642Z"
    },
    "trusted": true
   },
   "execution_count": 58,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1050' max='1050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1050/1050 05:06, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.130900</td>\n      <td>1.123047</td>\n      <td>0.535161</td>\n      <td>0.514056</td>\n      <td>0.566140</td>\n      <td>0.535161</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.967400</td>\n      <td>1.035493</td>\n      <td>0.593564</td>\n      <td>0.584514</td>\n      <td>0.623852</td>\n      <td>0.593564</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.813200</td>\n      <td>1.033806</td>\n      <td>0.595948</td>\n      <td>0.595574</td>\n      <td>0.616219</td>\n      <td>0.595948</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.473800</td>\n      <td>1.204051</td>\n      <td>0.598331</td>\n      <td>0.598494</td>\n      <td>0.609138</td>\n      <td>0.598331</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.197300</td>\n      <td>1.463763</td>\n      <td>0.600715</td>\n      <td>0.600646</td>\n      <td>0.611047</td>\n      <td>0.600715</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "bert_finetuner.evaluate_model()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:24:23.778177Z",
     "iopub.execute_input": "2024-06-25T10:24:23.778579Z",
     "iopub.status.idle": "2024-06-25T10:24:25.764460Z",
     "shell.execute_reply.started": "2024-06-25T10:24:23.778540Z",
     "shell.execute_reply": "2024-06-25T10:24:25.763515Z"
    },
    "trusted": true
   },
   "execution_count": 59,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "{'accuracy': 0.5744934445768772, 'f1': 0.5757213409698573, 'precision': 0.579769586214539, 'recall': 0.5744934445768772}\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Save the model (optional)\n",
    "bert_finetuner.save_model('Movie_Genre_Classifier')"
   ],
   "metadata": {
    "id": "dW7VuW9Vu9Q3",
    "execution": {
     "iopub.status.busy": "2024-06-25T10:24:25.765742Z",
     "iopub.execute_input": "2024-06-25T10:24:25.766021Z",
     "iopub.status.idle": "2024-06-25T10:24:48.748035Z",
     "shell.execute_reply.started": "2024-06-25T10:24:25.765997Z",
     "shell.execute_reply": "2024-06-25T10:24:48.747049Z"
    },
    "trusted": true
   },
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "text": "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\nModel saved.\n",
     "output_type": "stream"
    }
   ]
  }
 ]
}
